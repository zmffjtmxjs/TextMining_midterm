---
title: "텍스트 마이닝 중간고사"
author: "20161555-BGH"
date: '2022 5 1 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#라이브러리 로드
library(dplyr)
library(readr)
library(stringr)
library(textclean)
library(tidytext)
library(KoNLP)
library(ggplot2)
```

#### 문제1. 데이터 선정이유 구조 및 내용 설명
20대 대통령선거 출범식떄 윤석열과 이재명이 각자 연설한 내용입니다.

강의에서 실습에 사용하는 연설문 형식으로 같으나 제시된 문제 실습에 유효한 결과를 도출할 수 있을 것으로 판단하여
해당 데이터를 선정하였습니다.

###### 해당 분석은 실습을 목적으로 진행된 것이며 어떠한 정치적 의미를 가지지 않습니다.

#### 문제2. 가장 자주 사용된 단어 추출 및 빈도 그래프 만들기
##### 0) 데이터 전처리
```{r}
yun_speech =
  #파일 불러오기
  readLines("yun_speech.txt", encoding = "UTF-8") %>%
  #티블로 변환
  as_tibble() %>%
  #병합 시 구분을 위한 변수 추가
  mutate(president = "yun")

lee_speech =
  #파일 불러오기
  readLines("lee_speech.txt", encoding = "UTF-8") %>%
  #티블로 변환
  as_tibble() %>%
  #병합 시 구분을 위한 변수 추가
  mutate(president = "lee")

#두 개의 연설문을 하나로 병합
speeches = bind_rows(yun_speech, lee_speech) %>%
  select(president, value) %>% 
  #한글이 아닌 문자 전부 제거 ...
  mutate(value = str_replace_all(value, pattern = "[^가-힣]",  replacement = " "),
         #... 그리고 띄어쓰기가 2개이상 연속된 문자열을 하나로 압축
         value = str_squish(value))

#전처리 결과 확인
speeches
```

##### 1) 가장 자주 사용된 단어 추출
```{r}
#출범식 연설문 단어 추출
(speeches_freq = speeches %>%
  #전처리한 데이터를 형태소 분석기로 토큰화
  unnest_tokens(input = value, output = word, token = extractNoun) %>%
  #동일 단어 갯수를 세고 그 수를 기준으로 내림차순 정렬. 단, president 변수를 유지한다.
  count(president, word, sort = T) %>%
  #한 글자 이하인 모든 단어 제거
  filter(str_count(word) > 1))
```

#### 문제3. 오즈비 또는 TF-IDF 활용하여 분석하기

#### 문제4. 감정사전을 적용하여, 텍스트의 감정 경향을 분석하기

#### 문제5. 감정사전 수정하여 적용하고, 수정전과 비교분석하기

#### 추가점수문제. github로 버전관리 진행하고, 그 과정을 증비하기